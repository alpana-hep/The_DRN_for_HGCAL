#!/bin/bash -l

#SBATCH --time=100:00:00
#SBATCH --ntasks=4
#SBATCH --mem=150g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=asirohi@umn.edu
#SBATCH -p cms-1
#SBATCH --gres=gpu:v100:1
#SBATCH --job-name="Dlr_trimAhcal"

folder="/home/rusack/shared/pickles/HGCAL_TestBeam/Training_results/fix_wt_5M/Correct_training_5M/trimAhcal/epoch86beyond/dynamicLr/"
#v2->trueE, no semi
#v1->semi_dscb, loss fun= dscb

export PYTHONUNBUFFERED=1
module load cuda/10.1
module load cmake
module load gcc
module load graphviz
source activate torch1.8
./../../train $folder HGCAL_TestBeam/pkl_files/test_0to5M_fix_raw_ahcalTrim_up --idx_name all --nosemi --target ratio --in_layers 3 --mp_layers 2 --out_layers 2 --agg_layers 2 --max_lr 0.0001 --valid_batch_size 400 --train_batch_size 400 --acc_rate 15 --warm /home/rusack/shared/pickles/HGCAL_TestBeam/Training_results/fix_wt_5M/Correct_training_5M/trimAhcal/checkpoints/model_checkpoint_DynamicReductionNetwork_62405_3996cea28e_asirohi_025.pth.tar &>> $folder/training.log
#train $folder <DATA FOLDER> --arguments... &>> $folder/training.log
#<DATA FOLDER> options include:
#2018_UL_Particle_MC_30M: latest large dataset for electrons
#2018_UL_Photon_Refined: latest large dataset for photons
#2018_UL_photon_Refined/test: test version of the above with only ~8k particles
